{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ae70cbc-6d95-4afa-a7df-50d29877dde3",
   "metadata": {},
   "source": [
    "## Dialogue summarization task using prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "054772a8-8032-4f40-9719-0a93225458ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: torchdata in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.8.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchdata) (2.2.3)\n",
      "Requirement already satisfied: requests in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchdata) (2.32.3)\n",
      "Requirement already satisfied: torch>=2 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchdata) (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2->torchdata) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2->torchdata) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2->torchdata) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2->torchdata) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2->torchdata) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2->torchdata) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=2->torchdata) (75.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchdata) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchdata) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->torchdata) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=2->torchdata) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy->torch>=2->torchdata) (1.3.0)\n",
      "Requirement already satisfied: transformers[sentencepiece] in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.45.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[sentencepiece]) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[sentencepiece]) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[sentencepiece]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[sentencepiece]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[sentencepiece]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[sentencepiece]) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[sentencepiece]) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[sentencepiece]) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[sentencepiece]) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[sentencepiece]) (4.66.5)\n",
      "Requirement already satisfied: protobuf in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[sentencepiece]) (4.25.5)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[sentencepiece]) (0.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[sentencepiece]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[sentencepiece]) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.27->transformers[sentencepiece]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers[sentencepiece]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers[sentencepiece]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers[sentencepiece]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->transformers[sentencepiece]) (2024.8.30)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\lachhab choukr allah\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchdata\n",
    "!pip install transformers[sentencepiece]\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4f668e-ab5c-4782-9a50-e43d90091369",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a957fd-2795-427e-b05c-044e2d7afd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import GenerationConfig\n",
    "from transformers import T5Tokenizer\n",
    "from transformers import T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5aee5f84-70e3-48b4-9c1c-61d7070fcf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface_dataset_name = \"knkarthick/dialogsum\"\n",
    "\n",
    "dataset = load_dataset(huggingface_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49f1da19-f907-4b1f-8e18-2acd68383613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61879e59-59cb-4779-b2d7-9ec27699cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce70ed8-ee3d-41e2-8486-818f783020df",
   "metadata": {},
   "source": [
    "#### I - Summarize Dialogue without Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8e89c1-6595-4890-a26c-717af0a58ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT PROMPT:\n",
      "#Person1#: Ms. Dawson, I need you to take a dictation for me.\n",
      "#Person2#: Yes, sir...\n",
      "#Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\n",
      "#Person2#: Yes, sir. Go ahead.\n",
      "#Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\n",
      "#Person2#: Sir, does this apply to intra-office communications only? Or will it also restrict external communications?\n",
      "#Person1#: It should apply to all communications, not only in this office between employees, but also any outside communications.\n",
      "#Person2#: But sir, many employees use Instant Messaging to communicate with their clients.\n",
      "#Person1#: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we?\n",
      "#Person2#: This applies to internal and external communications.\n",
      "#Person1#: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads.\n",
      "#Person2#: Is that all?\n",
      "#Person1#: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\n",
      "------------------------------------------------\n",
      "BASELINE HUMAN SUMMARY:\n",
      "#Person1#: Ms. Dawson, I need you to take a dictation for me.\n"
     ]
    }
   ],
   "source": [
    "dialogue = dataset['test']['dialogue'][0]\n",
    "summary = dataset['test']['summary'][0]\n",
    "\n",
    "inputs = tokenizer(dialogue, return_tensors='pt').input_ids\n",
    "\n",
    "generation_config = GenerationConfig(max_new_tokens=50)\n",
    "\n",
    "response = model.generate(\n",
    "        inputs, \n",
    "        generation_config=generation_config\n",
    ")[0]\n",
    "\n",
    "output = tokenizer.decode(\n",
    "    response, \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(f'INPUT PROMPT:\\n{dialogue}')\n",
    "print('------------------------------------------------')\n",
    "print(f'BASELINE HUMAN SUMMARY:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56402884-1096-4981-aad9-74e322000ffd",
   "metadata": {},
   "source": [
    "#### II - Summarize Dialogue with an Instruction Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9e3a46-3904-48cc-88cc-5bb3e04a9928",
   "metadata": {},
   "source": [
    "**1 - Zero Shot Inference with an Instruction Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7d5ae47-26e5-4b2a-89b9-d62f819e1fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT PROMPT:\n",
      "#Person1#: Ms. Dawson, I need you to take a dictation for me.\n",
      "#Person2#: Yes, sir...\n",
      "#Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\n",
      "#Person2#: Yes, sir. Go ahead.\n",
      "#Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\n",
      "#Person2#: Sir, does this apply to intra-office communications only? Or will it also restrict external communications?\n",
      "#Person1#: It should apply to all communications, not only in this office between employees, but also any outside communications.\n",
      "#Person2#: But sir, many employees use Instant Messaging to communicate with their clients.\n",
      "#Person1#: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we?\n",
      "#Person2#: This applies to internal and external communications.\n",
      "#Person1#: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads.\n",
      "#Person2#: Is that all?\n",
      "#Person1#: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\n",
      "------------------------------------------------\n",
      "MODEL GENERATION - ZERO SHOT:\n",
      "The memo is to be distributed to all employees by this afternoon.\n"
     ]
    }
   ],
   "source": [
    "dialogue = dataset['test']['dialogue'][0]\n",
    "summary = dataset['test']['summary'][0]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "\n",
    "generation_config = GenerationConfig(max_new_tokens=50)\n",
    "\n",
    "response = model.generate(\n",
    "        inputs, \n",
    "        generation_config=generation_config\n",
    ")[0]\n",
    "\n",
    "output = tokenizer.decode(\n",
    "    response, \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(f'INPUT PROMPT:\\n{dialogue}')\n",
    "print('------------------------------------------------')\n",
    "print(f'MODEL GENERATION - ZERO SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd152ec-8d19-4b6a-b678-4d9662469e2b",
   "metadata": {},
   "source": [
    "**2 - One Shot Inference with an Instruction Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "170c8ce8-1d85-43fd-b9a3-e410de01ef44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (764 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT PROMPT:\n",
      "#Person1#: Ms. Dawson, I need you to take a dictation for me.\n",
      "#Person2#: Yes, sir...\n",
      "#Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\n",
      "#Person2#: Yes, sir. Go ahead.\n",
      "#Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\n",
      "#Person2#: Sir, does this apply to intra-office communications only? Or will it also restrict external communications?\n",
      "#Person1#: It should apply to all communications, not only in this office between employees, but also any outside communications.\n",
      "#Person2#: But sir, many employees use Instant Messaging to communicate with their clients.\n",
      "#Person1#: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we?\n",
      "#Person2#: This applies to internal and external communications.\n",
      "#Person1#: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads.\n",
      "#Person2#: Is that all?\n",
      "#Person1#: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\n",
      "------------------------------------------------\n",
      "MODEL GENERATION - ONE SHOT:\n",
      "Ms. Dawson takes a dictation for #Person1 about prohibiting the use of Instant Messaging programs in the office.\n"
     ]
    }
   ],
   "source": [
    "dialogue = dataset['test']['dialogue'][0]\n",
    "summary = dataset['test']['summary'][0]\n",
    "dialogue_exp = dataset['test']['dialogue'][2]\n",
    "summary_exp = dataset['test']['summary'][2]\n",
    "\n",
    "prompt = ''\n",
    "\n",
    "prompt += f\"\"\"\n",
    "Dialogue:\n",
    "\n",
    "{dialogue_exp}\n",
    "\n",
    "What was going on?\n",
    "{summary_exp}\n",
    "\"\"\"\n",
    "\n",
    "prompt += f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "\n",
    "generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.1)\n",
    "\n",
    "response = model.generate(\n",
    "        inputs, \n",
    "        generation_config=generation_config\n",
    ")[0]\n",
    "\n",
    "output = tokenizer.decode(\n",
    "    response, \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(f'INPUT PROMPT:\\n{dialogue}')\n",
    "print('------------------------------------------------')\n",
    "print(f'MODEL GENERATION - ONE SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae74cf3-094b-4d27-b68b-171ba4691069",
   "metadata": {},
   "source": [
    "**3 - Few Shot Inference with an Instruction Prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78bcfe62-98a9-4a52-806a-e0043a13fe43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT PROMPT:\n",
      "#Person1#: Ms. Dawson, I need you to take a dictation for me.\n",
      "#Person2#: Yes, sir...\n",
      "#Person1#: This should go out as an intra-office memorandum to all employees by this afternoon. Are you ready?\n",
      "#Person2#: Yes, sir. Go ahead.\n",
      "#Person1#: Attention all staff... Effective immediately, all office communications are restricted to email correspondence and official memos. The use of Instant Message programs by employees during working hours is strictly prohibited.\n",
      "#Person2#: Sir, does this apply to intra-office communications only? Or will it also restrict external communications?\n",
      "#Person1#: It should apply to all communications, not only in this office between employees, but also any outside communications.\n",
      "#Person2#: But sir, many employees use Instant Messaging to communicate with their clients.\n",
      "#Person1#: They will just have to change their communication methods. I don't want any - one using Instant Messaging in this office. It wastes too much time! Now, please continue with the memo. Where were we?\n",
      "#Person2#: This applies to internal and external communications.\n",
      "#Person1#: Yes. Any employee who persists in using Instant Messaging will first receive a warning and be placed on probation. At second offense, the employee will face termination. Any questions regarding this new policy may be directed to department heads.\n",
      "#Person2#: Is that all?\n",
      "#Person1#: Yes. Please get this memo typed up and distributed to all employees before 4 pm.\n",
      "------------------------------------------------\n",
      "MODEL GENERATION - FEW SHOT:\n",
      "#Person1#: Ms. Dawson, I need you to take a dictation for me. #Person2#: Yes, sir... #Person1#: This should go out as an intra-office\n"
     ]
    }
   ],
   "source": [
    "dialogue = dataset['test']['dialogue'][0]\n",
    "summary = dataset['test']['summary'][0]\n",
    "\n",
    "prompt = ''\n",
    "\n",
    "for i in range(1,4):\n",
    "    \n",
    "    dialogue_exp = dataset['test']['dialogue'][i]\n",
    "    summary_exp = dataset['test']['summary'][i]\n",
    "    prompt += f\"\"\"\n",
    "        Dialogue:\n",
    "        \n",
    "        {dialogue_exp}\n",
    "        \n",
    "        What was going on?\n",
    "        {summary_exp}\n",
    "    \"\"\"\n",
    "\n",
    "prompt += f\"\"\"\n",
    "Summarize the following conversation.\n",
    "\n",
    "{dialogue}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors='pt').input_ids\n",
    "\n",
    "generation_config = GenerationConfig(max_new_tokens=50, do_sample=True, temperature=0.3)\n",
    "\n",
    "response = model.generate(\n",
    "        inputs, \n",
    "        generation_config=generation_config\n",
    ")[0]\n",
    "\n",
    "output = tokenizer.decode(\n",
    "    response, \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(f'INPUT PROMPT:\\n{dialogue}')\n",
    "print('------------------------------------------------')\n",
    "print(f'MODEL GENERATION - FEW SHOT:\\n{output}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12123341-86fa-48ed-9ea2-922d6cd1bb6c",
   "metadata": {},
   "source": [
    "In this case, few shot did not provide much of an improvement over one shot inference. And, anything above 5 or 6 shot will typically not help much, either. Also, you need to make sure that you do not exceed the model's input-context length which, in our case, if 512 tokens. Anything above the context length will be ignored."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
